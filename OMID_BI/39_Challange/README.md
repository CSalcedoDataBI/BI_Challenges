# CHALLENGE 39

Este repositorio contiene mis soluciones al Challenge 39, tal como se describe en el reto original proporcionado por Omid Motamedisedeh en su LinkedIn.

## Descripci칩n del Desaf칤o

El desaf칤o requiere:
Descubramos un m칠todo ingenioso para abordar el desaf칤o 39: 춰Transformaci칩n!
De la lista de productos de la tabla de preguntas, extraiga la lista 칰nica de todos los c칩digos de producto.

![Descripci칩n del desaf칤o](https://github.com/cristobalsalcedo90/BI_Challenges/blob/0a2c380e0018358caae34ba18803c31a67990a05/OMID_BI/39_Challange/Files/Omid.png)

La fuente del desaf칤o puede encontrarse en el perfil de LinkedIn de Omid Motamedisedeh: [
Omid Motamedisedeh](https://www.linkedin.com/posts/omid-motamedisedeh-74aba166_excelchallenge-powerquerychllenge-excel-activity-7186830879980191745-kfBw?utm_source=share&utm_medium=member_desktop)

## Soluciones

### Soluci칩n usando PySpark 游 en un Notebook en MicrosoftFabric

Aqu칤 muestro c칩mo abord칠 el desaf칤o usando PySpark, destacando el procesamiento distribuido para manejar datos a gran escala.

![Soluci칩n PySpark](https://github.com/cristobalsalcedo90/BI_Challenges/blob/0a2c380e0018358caae34ba18803c31a67990a05/OMID_BI/39_Challange/Files/PySpark.PNG)

Copiar Codigo aqu칤:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, explode, collect_set, array
import pandas as pd

spark = SparkSession.builder.appName("UniqueValuesExtraction").getOrCreate()
file_path = "/lakehouse/default/Files/ChallengeOmid/CH-039 Transformation.xlsx"
pandas_df = pd.read_excel(file_path, usecols=[1, 2, 3, 4], nrows=9)

df = spark.createDataFrame(pandas_df)
df_exploded = df.withColumn("Result - Unique Code", explode(array(*df.columns)))

unique_values = df_exploded.select("Result - Unique Code").na.drop() \
                         .distinct().sort("Result - Unique Code")
unique_values.show()



```
## Detalles de las Funciones Usadas

- **SparkSession**: Esta clase es un punto de entrada a las funcionalidades de Spark SQL. Permite la creaci칩n de DataFrames y la ejecuci칩n de operaciones SQL, facilitando el procesamiento distribuido de grandes vol칰menes de datos. La configuraci칩n del entorno de Spark y el manejo de recursos tambi칠n se gestionan a trav칠s de esta sesi칩n.

- **read_excel**: Funci칩n de Pandas utilizada para leer un archivo Excel. Permite especificar las columnas a importar y la cantidad de filas a leer, lo que es 칰til para limitar la carga de datos en memoria cuando se trabaja con archivos grandes o detallados. Al cargar los datos con Pandas, se aprovecha la facilidad de manipulaci칩n de datos de Pandas antes de pasar los datos a Spark.

- **createDataFrame**: Este m칠todo de `SparkSession` convierte estructuras de datos compatibles, como DataFrames de Pandas, en DataFrames de Spark. Esta conversi칩n es esencial para pasar de la manipulaci칩n de datos con Pandas al procesamiento escalable con Spark. Al utilizar este m칠todo, se pueden aprovechar las optimizaciones de Spark para el procesamiento distribuido de datos mientras se mantienen las transformaciones iniciales realizadas en Pandas.

- **explode**: Una funci칩n de PySpark que se utiliza para transformar cada elemento de una lista en una fila separada, replicando los valores de las otras columnas en cada nueva fila. Esto es especialmente 칰til para desnormalizar columnas que contienen listas o m칰ltiples valores empaquetados en una sola celda.

- **array**: En PySpark, esta funci칩n crea una columna de tipo arreglo a partir de varias columnas del DataFrame. Se utiliza com칰nmente en combinaci칩n con `explode` para desestructurar arrays y manejar datos a nivel de elemento.

- **distinct**: M칠todo utilizado en DataFrames de PySpark para eliminar filas duplicadas. Es fundamental para asegurar que los an치lisis o resultados finales no sean sesgados por datos repetidos.

- **sort**: Este m칠todo ordena las filas del DataFrame seg칰n los valores de una o m치s columnas. En el contexto de este script, se usa para ordenar los valores 칰nicos extra칤dos, permitiendo una presentaci칩n m치s organizada y comprensible de los datos.

- **na.drop**: M칠todo para eliminar filas que contienen valores NaN en el DataFrame. Esto ayuda a mantener la calidad de los datos, asegurando que las operaciones y an치lisis subsiguientes se realicen sobre datos completos y v치lidos.



### Soluci칩n usando Python en un Notebook en MicrosoftFabric

Aqu칤 est치 mi soluci칩n implementada en Python puro, aprovechando las bibliotecas de an치lisis de datos para una soluci칩n eficiente y escalable.

![Soluci칩n Python](https://github.com/cristobalsalcedo90/BI_Challenges/blob/0a2c380e0018358caae34ba18803c31a67990a05/OMID_BI/39_Challange/Files/Python.png)

Copiar Codigo aqu칤:
```python
import pandas as pd
file_path = "/lakehouse/default/Files/ChallengeOmid/CH-039 Transformation.xlsx"
df = pd.read_excel(file_path, usecols=[1, 2, 3, 4], nrows=9)
df_melted = df.melt(var_name='Attribute', value_name='Result - Unique Code')
unique_values = pd.Series(df_melted['Result - Unique Code'].dropna() \
                .unique()).sort_values().tolist()
result_df = pd.DataFrame({"Result - Unique Code": unique_values})
print(result_df)
```
# Extracci칩n y Ordenamiento de Valores 칔nicos en Python

Este script utiliza Python y Pandas para leer datos desde un archivo Excel, transformar estos datos de un formato ancho a uno largo, y extraer y ordenar valores 칰nicos de ciertas columnas. El objetivo es simplificar la manipulaci칩n de datos y facilitar an치lisis posteriores o integraciones.

## C칩mo Funciona

1. **Leer Datos**: El script comienza leyendo un archivo Excel especificado, seleccionando ciertas columnas y un n칰mero limitado de filas.
2. **Transformar Datos**: Utiliza la funci칩n `melt` de Pandas para transformar el DataFrame de un formato ancho a uno m치s largo.
3. **Extracci칩n de Valores 칔nicos**: A partir de los datos transformados, se extraen valores 칰nicos, excluyendo cualquier dato faltante (NaN).
4. **Ordenamiento y Visualizaci칩n**: Los valores 칰nicos son ordenados y convertidos en un nuevo DataFrame para su f치cil visualizaci칩n.



### Soluci칩n Power Query


Aqu칤 est치 mi soluci칩n implementada en Power Query.

![Soluci칩n Power Query](https://github.com/cristobalsalcedo90/BI_Challenges/blob/9ed693393f32c097d5445725480cf6e356f9111b/OMID_BI/39_Challange/Files/PowerQuery.PNG)

췂췂췂pq
let
  Source = Excel.CurrentWorkbook(){[Name = "Table2"]}[Content], 
  #"Unpivoted Other Columns" = Table.FromList(
    List.Sort(List.Distinct(Table.UnpivotOtherColumns(Source, {}, "Attribute", "Value")[Value])), 
    null, 
    {"Result - Unique Code"}
  )
in
  #"Unpivoted Other Columns"

췂췂췂

## Agradecimientos y Referencias

Un agradecimiento especial a la comunidad de [Omid Motamedisedeh](https://www.linkedin.com/in/omid-motamedisedeh-74aba166/) por proporcionar estos desafiantes y enriquecedores problemas que nos permiten crecer profesionalmente en el campo del BI.

## 쮺칩mo utilizar este repositorio?

Puede clonar este repositorio y ejecutar los notebooks proporcionados para ver c칩mo se implementaron las soluciones. Se proporcionan instrucciones detalladas dentro de cada notebook.

## Contacto

Si tienes alguna pregunta o deseas conectarte, no dudes en visitar mi perfil de LinkedIn.

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Cristobal%20Salcedo-blue)](https://www.linkedin.com/in/cristobal-salcedo)

---

Recuerda reemplazar los enlaces y las descripciones con la informaci칩n correcta y actualizada. Este c칩digo markdown puede ser colocado directamente en tu archivo README.md en GitHub para presentar tu soluci칩n de una manera estructurada y profesional.
