# CHALLENGE 39

Este repositorio contiene mis soluciones al Challenge 39, tal como se describe en el reto original proporcionado por Omid Motamedisedeh en su LinkedIn.

## Descripci贸n del Desaf铆o

El desaf铆o requiere:
Descubramos un m茅todo ingenioso para abordar el desaf铆o 39: 隆Transformaci贸n!
De la lista de productos de la tabla de preguntas, extraiga la lista 煤nica de todos los c贸digos de producto.

![Descripci贸n del desaf铆o](https://github.com/cristobalsalcedo90/BI_Challenges/blob/0a2c380e0018358caae34ba18803c31a67990a05/OMID_BI/39_Challange/Files/Omid.png)

La fuente del desaf铆o puede encontrarse en el perfil de LinkedIn de Omid Motamedisedeh: [
Omid Motamedisedeh](https://www.linkedin.com/posts/omid-motamedisedeh-74aba166_excelchallenge-powerquerychllenge-excel-activity-7186830879980191745-kfBw?utm_source=share&utm_medium=member_desktop)

## Soluciones

### Soluci贸n usando PySpark  en un Notebook en MicrosoftFabric

Aqu铆 muestro c贸mo abord茅 el desaf铆o usando PySpark, destacando el procesamiento distribuido para manejar datos a gran escala.

![Soluci贸n PySpark](https://github.com/cristobalsalcedo90/BI_Challenges/blob/0a2c380e0018358caae34ba18803c31a67990a05/OMID_BI/39_Challange/Files/PySpark.PNG)

Copiar Codigo aqu铆:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, explode, collect_set, array
import pandas as pd

spark = SparkSession.builder.appName("UniqueValuesExtraction").getOrCreate()
file_path = "/lakehouse/default/Files/ChallengeOmid/CH-039 Transformation.xlsx"
pandas_df = pd.read_excel(file_path, usecols=[1, 2, 3, 4], nrows=9)

df = spark.createDataFrame(pandas_df)
df_exploded = df.withColumn("Result - Unique Code", explode(array(*df.columns)))

unique_values = df_exploded.select("Result - Unique Code").na.drop() \
                         .distinct().sort("Result - Unique Code")
unique_values.show()



```
## Detalles de las Funciones Usadas

- **SparkSession**: Esta clase es un punto de entrada a las funcionalidades de Spark SQL. Permite la creaci贸n de DataFrames y la ejecuci贸n de operaciones SQL, facilitando el procesamiento distribuido de grandes vol煤menes de datos. La configuraci贸n del entorno de Spark y el manejo de recursos tambi茅n se gestionan a trav茅s de esta sesi贸n.

- **read_excel**: Funci贸n de Pandas utilizada para leer un archivo Excel. Permite especificar las columnas a importar y la cantidad de filas a leer, lo que es 煤til para limitar la carga de datos en memoria cuando se trabaja con archivos grandes o detallados. Al cargar los datos con Pandas, se aprovecha la facilidad de manipulaci贸n de datos de Pandas antes de pasar los datos a Spark.

- **createDataFrame**: Este m茅todo de `SparkSession` convierte estructuras de datos compatibles, como DataFrames de Pandas, en DataFrames de Spark. Esta conversi贸n es esencial para pasar de la manipulaci贸n de datos con Pandas al procesamiento escalable con Spark. Al utilizar este m茅todo, se pueden aprovechar las optimizaciones de Spark para el procesamiento distribuido de datos mientras se mantienen las transformaciones iniciales realizadas en Pandas.

- **explode**: Una funci贸n de PySpark que se utiliza para transformar cada elemento de una lista en una fila separada, replicando los valores de las otras columnas en cada nueva fila. Esto es especialmente 煤til para desnormalizar columnas que contienen listas o m煤ltiples valores empaquetados en una sola celda.

- **array**: En PySpark, esta funci贸n crea una columna de tipo arreglo a partir de varias columnas del DataFrame. Se utiliza com煤nmente en combinaci贸n con `explode` para desestructurar arrays y manejar datos a nivel de elemento.

- **distinct**: M茅todo utilizado en DataFrames de PySpark para eliminar filas duplicadas. Es fundamental para asegurar que los an谩lisis o resultados finales no sean sesgados por datos repetidos.

- **sort**: Este m茅todo ordena las filas del DataFrame seg煤n los valores de una o m谩s columnas. En el contexto de este script, se usa para ordenar los valores 煤nicos extra铆dos, permitiendo una presentaci贸n m谩s organizada y comprensible de los datos.

- **na.drop**: M茅todo para eliminar filas que contienen valores NaN en el DataFrame. Esto ayuda a mantener la calidad de los datos, asegurando que las operaciones y an谩lisis subsiguientes se realicen sobre datos completos y v谩lidos.



### Soluci贸n usando Python en un Notebook en MicrosoftFabric

Aqu铆 est谩 mi soluci贸n implementada en Python puro, aprovechando las bibliotecas de an谩lisis de datos para una soluci贸n eficiente y escalable.

![Soluci贸n Python](https://github.com/cristobalsalcedo90/BI_Challenges/blob/0a2c380e0018358caae34ba18803c31a67990a05/OMID_BI/39_Challange/Files/Python.png)

Copiar Codigo aqu铆:
```python
import pandas as pd
file_path = "/lakehouse/default/Files/ChallengeOmid/CH-039 Transformation.xlsx"
df = pd.read_excel(file_path, usecols=[1, 2, 3, 4], nrows=9)
df_melted = df.melt(var_name='Attribute', value_name='Result - Unique Code')
unique_values = pd.Series(df_melted['Result - Unique Code'].dropna() \
                .unique()).sort_values().tolist()
result_df = pd.DataFrame({"Result - Unique Code": unique_values})
print(result_df)
```
# Extracci贸n y Ordenamiento de Valores nicos en Python

Este script utiliza Python y Pandas para leer datos desde un archivo Excel, transformar estos datos de un formato ancho a uno largo, y extraer y ordenar valores 煤nicos de ciertas columnas. El objetivo es simplificar la manipulaci贸n de datos y facilitar an谩lisis posteriores o integraciones.

## C贸mo Funciona

1. **Leer Datos**: El script comienza leyendo un archivo Excel especificado, seleccionando ciertas columnas y un n煤mero limitado de filas.
2. **Transformar Datos**: Utiliza la funci贸n `melt` de Pandas para transformar el DataFrame de un formato ancho a uno m谩s largo.
3. **Extracci贸n de Valores nicos**: A partir de los datos transformados, se extraen valores 煤nicos, excluyendo cualquier dato faltante (NaN).
4. **Ordenamiento y Visualizaci贸n**: Los valores 煤nicos son ordenados y convertidos en un nuevo DataFrame para su f谩cil visualizaci贸n.



### Soluci贸n Power Query


Aqu铆 est谩 mi soluci贸n implementada en Power Query.

![Soluci贸n Power Query](https://github.com/cristobalsalcedo90/BI_Challenges/blob/9ed693393f32c097d5445725480cf6e356f9111b/OMID_BI/39_Challange/Files/PowerQuery.PNG)

```pq
let
  Source = Excel.CurrentWorkbook(){[Name = "Table2"]}[Content], 
  #"Unpivoted Other Columns" = Table.FromList(
    List.Sort(List.Distinct(Table.UnpivotOtherColumns(Source, {}, "Attribute", "Value")[Value])), 
    null, 
    {"Result - Unique Code"}
  )
in
  #"Unpivoted Other Columns"

```

## Agradecimientos y Referencias

Un agradecimiento especial a la comunidad de [Omid Motamedisedeh](https://www.linkedin.com/in/omid-motamedisedeh-74aba166/) por proporcionar estos desafiantes y enriquecedores problemas que nos permiten crecer profesionalmente en el campo del BI.

## 驴C贸mo utilizar este repositorio?

Puede clonar este repositorio y ejecutar los notebooks proporcionados para ver c贸mo se implementaron las soluciones. Se proporcionan instrucciones detalladas dentro de cada notebook.

## Contacto

Si tienes alguna pregunta o deseas conectarte, no dudes en visitar mi perfil de LinkedIn.

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Cristobal%20Salcedo-blue)](https://www.linkedin.com/in/cristobal-salcedo)

---

Recuerda reemplazar los enlaces y las descripciones con la informaci贸n correcta y actualizada. Este c贸digo markdown puede ser colocado directamente en tu archivo README.md en GitHub para presentar tu soluci贸n de una manera estructurada y profesional.
